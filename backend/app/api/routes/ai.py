from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import time
from app.core.ai_manager import AIManager
from app.core.advanced_smart_conversation_manager import advanced_smart_conversation_manager

router = APIRouter()

class ChatRequest(BaseModel):
    provider: str = Field(..., description="AI provider name")
    model: str = Field(..., description="Model name")
    messages: List[Dict[str, str]] = Field(..., description="Chat messages")
    api_key: str = Field(..., description="API key")
    base_url: Optional[str] = Field(None, description="Custom base URL")
    temperature: Optional[float] = Field(None, description="Temperature for generation")
    max_tokens: Optional[int] = Field(None, description="Maximum tokens to generate")
    top_p: Optional[float] = Field(None, description="Top-p sampling")
    frequency_penalty: Optional[float] = Field(None, description="Frequency penalty")
    presence_penalty: Optional[float] = Field(None, description="Presence penalty")

class TestConnectionRequest(BaseModel):
    provider: str = Field(..., description="AI provider name")
    api_key: str = Field(..., description="API key")
    base_url: Optional[str] = Field(None, description="Custom base URL")

class SmartConversationRequest(BaseModel):
    project_path: str = Field(..., description="Project path")
    conversation_id: Optional[str] = Field(None, description="Conversation ID")
    message: Optional[str] = Field(None, description="User message")

class ProviderConfig(BaseModel):
    name: str
    icon: str
    description: str
    models: List[str]
    default_base_url: str
    requires_api_key: bool

ai_manager = AIManager()

@router.get("/providers")
async def get_providers() -> Dict[str, ProviderConfig]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„AIä¾›åº”å•†é…ç½®"""
    return ai_manager.get_available_providers()

@router.post("/chat")
async def chat(request: ChatRequest) -> Dict[str, Any]:
    """å‘é€èŠå¤©æ¶ˆæ¯åˆ°AI"""
    try:
        # ä½¿ç”¨è¯·æ±‚ä¸­çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
        default_params = ai_manager.get_default_ai_params()
        
        response = await ai_manager.chat(
            provider=request.provider,
            model=request.model,
            messages=request.messages,
            api_key=request.api_key,
            base_url=request.base_url,
            temperature=request.temperature if request.temperature is not None else default_params["temperature"],
            max_tokens=request.max_tokens if request.max_tokens is not None else default_params["max_tokens"],
            top_p=request.top_p if request.top_p is not None else default_params.get("top_p", 1.0),
            frequency_penalty=request.frequency_penalty if request.frequency_penalty is not None else default_params.get("frequency_penalty", 0.0),
            presence_penalty=request.presence_penalty if request.presence_penalty is not None else default_params.get("presence_penalty", 0.0)
        )
        return response
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI service error: {str(e)}")

@router.post("/test-connection")
async def test_connection(request: TestConnectionRequest) -> Dict[str, bool]:
    """æµ‹è¯•AIä¾›åº”å•†è¿æ¥"""
    try:
        success = await ai_manager.test_connection(
            provider=request.provider,
            api_key=request.api_key,
            base_url=request.base_url
        )
        return {"success": success}
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.get("/models/{provider}")
async def get_models(provider: str) -> List[str]:
    """è·å–æŒ‡å®šä¾›åº”å•†çš„å¯ç”¨æ¨¡å‹"""
    config = ai_manager.get_provider_config(provider)
    if not config:
        raise HTTPException(status_code=404, detail="Provider not found")
    return config.get("models", [])

# è¾…åŠ©å‡½æ•°
def format_file_tree_for_ai(tree: Dict[str, Any], indent: int = 0) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶æ ‘ä¸ºAIå¯è¯»çš„å­—ç¬¦ä¸²"""
    if tree.get("type") == "file":
        return "  " * indent + f"ğŸ“„ {tree['name']}\n"

    result = "  " * indent + f"ğŸ“ {tree['name']}/\n"
    for child in tree.get("children", []):
        result += format_file_tree_for_ai(child, indent + 1)
    return result

# æ™ºèƒ½å¯¹è¯ç«¯ç‚¹
@router.post("/smart-conversation/start")
async def start_smart_conversation(request: SmartConversationRequest) -> Dict[str, Any]:
    """å¼€å§‹æ™ºèƒ½å¯¹è¯ä¼šè¯"""
    try:
        # ç”Ÿæˆä¼šè¯ID
        conversation_id = f"conv_{int(time.time() * 1000)}"
        
        # è·å–é¡¹ç›®æ–‡ä»¶ç»“æ„
        from app.core.git_manager import GitManager
        git_manager = GitManager()
        # é¦–å…ˆæ·»åŠ é¡¹ç›®åˆ°ç®¡ç†å™¨
        git_manager.add_project(request.project_path)
        project = git_manager.get_project(request.project_path)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        file_tree = project.get_file_tree(max_depth=2)
        
        # æ„å»ºåˆå§‹ç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·åˆ†æé¡¹ç›®æ¶æ„ã€ä»£ç ç»“æ„å’ŒæŠ€æœ¯æ ˆã€‚

å½“å‰åˆ†æçš„é¡¹ç›®è·¯å¾„: {request.project_path}
é¡¹ç›®æ–‡ä»¶ç»“æ„:
{format_file_tree_for_ai(file_tree)}

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥è·å–æ›´å¤šä¿¡æ¯ï¼š
1. read_project_file - è¯»å–é¡¹ç›®æ–‡ä»¶å†…å®¹
2. list_project_files - åˆ—å‡ºé¡¹ç›®æ–‡ä»¶ç»“æ„
3. get_file_metadata - è·å–æ–‡ä»¶å…ƒæ•°æ®

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œæ™ºèƒ½åœ°ä½¿ç”¨è¿™äº›å·¥å…·æ¥è·å–æ‰€éœ€ä¿¡æ¯ï¼Œç„¶åè¿›è¡Œåˆ†æå’Œå›ç­”ã€‚
"""

        return {
            "conversation_id": conversation_id,
            "system_prompt": system_prompt,
            "project_path": request.project_path
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start conversation: {str(e)}")

@router.post("/smart-conversation/chat")
async def smart_chat(request: SmartConversationRequest) -> Dict[str, Any]:
    """æ™ºèƒ½å¯¹è¯èŠå¤©"""
    try:
        # ä½¿ç”¨é«˜çº§æ™ºèƒ½å¯¹è¯ç®¡ç†å™¨å¤„ç†è¯·æ±‚
        result = await advanced_smart_conversation_manager.process_smart_chat(
            request.conversation_id or f"conv_{int(time.time() * 1000)}",
            request.project_path,
            request.message or ""
        )
        
        return {
            "response": result["response"],
            "conversation_id": result["conversation_id"],
            "tool_calls": result["tool_calls"],
            "analysis_context": result.get("analysis_context", {})
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Smart chat failed: {str(e)}")

@router.post("/smart-conversation/end")
async def end_smart_conversation(request: SmartConversationRequest) -> Dict[str, Any]:
    """ç»“æŸæ™ºèƒ½å¯¹è¯ä¼šè¯"""
    return {
        "success": True,
        "message": "Conversation ended successfully",
        "conversation_id": request.conversation_id
    }
