"""
ä¸Šä¸‹æ–‡å‹ç¼©ç­–ç•¥

å‚è€ƒ Cline çš„å®ç°ï¼š
1. æ¸è¿›å¼å‹ç¼©ï¼šå…ˆä¼˜åŒ–ï¼Œå†æˆªæ–­ï¼Œæœ€åæ‘˜è¦
2. æ™ºèƒ½æ–‡ä»¶å¤„ç†ï¼šè¯†åˆ«é‡å¤çš„æ–‡ä»¶è¯»å–
3. åˆ†å±‚æ¶ˆæ¯ç®¡ç†ï¼šä¿ç•™å…³é”®æ¶ˆæ¯ï¼Œå‹ç¼©å†å²æ¶ˆæ¯
"""

import json
import logging
from typing import Dict, List, Any, Optional, Tuple
from enum import Enum

from app.core.context.token_counter import TokenCounter
from app.core.ai_manager import AIManager

logger = logging.getLogger(__name__)


class CompressionLevel(Enum):
    """å‹ç¼©çº§åˆ«"""
    NONE = "none"  # ä¸å‹ç¼©
    LIGHT = "light"  # è½»åº¦å‹ç¼©ï¼ˆä¿ç•™ 75%ï¼‰
    MEDIUM = "medium"  # ä¸­åº¦å‹ç¼©ï¼ˆä¿ç•™ 50%ï¼‰
    AGGRESSIVE = "aggressive"  # æ¿€è¿›å‹ç¼©ï¼ˆä¿ç•™ 25%ï¼‰


class CompressionStrategy:
    """
    ä¸Šä¸‹æ–‡å‹ç¼©ç­–ç•¥

    å‚è€ƒ Cline çš„ ContextManager å®ç°
    """

    # å‹ç¼©é˜ˆå€¼
    SHOULD_COMPRESS_THRESHOLD = 0.8  # å½“ä½¿ç”¨é‡è¶…è¿‡ 80% æ—¶å‹ç¼©
    MUST_COMPRESS_THRESHOLD = 0.95  # å½“ä½¿ç”¨é‡è¶…è¿‡ 95% æ—¶å¼ºåˆ¶å‹ç¼©

    # ä¿ç•™ç­–ç•¥
    KEEP_FIRST_N_PAIRS = 1  # ä¿ç•™å‰ N è½®å¯¹è¯
    KEEP_LAST_N_PAIRS = 2  # ä¿ç•™æœ€å N è½®å¯¹è¯

    def __init__(self, ai_manager: Optional[AIManager] = None):
        self.ai_manager = ai_manager or AIManager()
        self.token_counter = TokenCounter()

    def should_compress(
        self,
        messages: List[Dict[str, Any]],
        model: str,
        threshold: Optional[float] = None
    ) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©

        Args:
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨
            model: æ¨¡å‹åç§°
            threshold: è‡ªå®šä¹‰é˜ˆå€¼

        Returns:
            æ˜¯å¦éœ€è¦å‹ç¼©
        """
        threshold = threshold or self.SHOULD_COMPRESS_THRESHOLD
        info = self.token_counter.get_compression_info(messages, model)
        return info["usage_percentage"] >= threshold

    def must_compress(self, messages: List[Dict[str, Any]], model: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¿…é¡»å‹ç¼©"""
        info = self.token_counter.get_compression_info(messages, model)
        return info["must_compress"]

    async def compress_conversation_history(
        self,
        messages: List[Dict[str, Any]],
        model: str,
        ai_config: Dict[str, Any],
        compression_level: Optional[CompressionLevel] = None
    ) -> List[Dict[str, Any]]:
        """
        å‹ç¼©å¯¹è¯å†å²

        å‚è€ƒ Cline çš„åˆ†å±‚å‹ç¼©ç­–ç•¥ï¼š
        1. ä¿ç•™ç³»ç»Ÿæç¤ºè¯ï¼ˆå§‹ç»ˆä¿ç•™ï¼‰
        2. ä¿ç•™ç¬¬ä¸€è½®å’Œæœ€åå‡ è½®å¯¹è¯
        3. ä¸­é—´çš„æ¶ˆæ¯æŒ‰æ¯”ä¾‹æˆªæ–­æˆ–æ‘˜è¦

        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            model: æ¨¡å‹åç§°
            ai_config: AI é…ç½®
            compression_level: å‹ç¼©çº§åˆ«

        Returns:
            å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if len(messages) <= 4:
            # æ¶ˆæ¯å¤ªå°‘ï¼Œä¸éœ€è¦å‹ç¼©
            return messages

        print(f"\nğŸ—œï¸  å¼€å§‹å‹ç¼©ä¸Šä¸‹æ–‡...")
        print(f"   - åŸå§‹æ¶ˆæ¯æ•°: {len(messages)}")

        # ç¡®å®šå‹ç¼©çº§åˆ«
        if not compression_level:
            compression_level = self._determine_compression_level(messages, model)

        print(f"   - å‹ç¼©çº§åˆ«: {compression_level.value}")

        # 1. æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœæœ‰ï¼‰
        system_messages = [msg for msg in messages if msg.get("role") == "system"]
        non_system_messages = [msg for msg in messages if msg.get("role") != "system"]

        # 2. ä¿ç•™ç¬¬ä¸€è½®å’Œæœ€åå‡ è½®å¯¹è¯
        compressed = []

        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        compressed.extend(system_messages)

        # ä¿ç•™ç¬¬ä¸€è½®å¯¹è¯
        if len(non_system_messages) >= 2:
            compressed.extend(non_system_messages[:2])
        else:
            compressed.extend(non_system_messages)
            return compressed

        # è®¡ç®—è¦ä¿ç•™çš„æ¶ˆæ¯æ•°é‡
        total_pairs = len(non_system_messages) // 2
        keep_first = self.KEEP_FIRST_N_PAIRS * 2
        keep_last = self.KEEP_LAST_N_PAIRS * 2

        if compression_level == CompressionLevel.LIGHT:
            # ä¿ç•™ 75%
            keep_middle = max(0, total_pairs - int(total_pairs * 0.25)) * 2
        elif compression_level == CompressionLevel.MEDIUM:
            # ä¿ç•™ 50%
            keep_middle = max(0, total_pairs - int(total_pairs * 0.5)) * 2
        else:  # AGGRESSIVE
            # ä¿ç•™ 25%
            keep_middle = max(0, total_pairs - int(total_pairs * 0.75)) * 2

        # ä¸­é—´éƒ¨åˆ†
        middle_start = keep_first
        middle_end = len(non_system_messages) - keep_last

        if middle_start < middle_end:
            middle_messages = non_system_messages[middle_start:middle_end]

            if compression_level == CompressionLevel.AGGRESSIVE:
                # æ¿€è¿›å‹ç¼©ï¼šä½¿ç”¨ AI æ‘˜è¦
                summary = await self._summarize_messages(middle_messages, ai_config)
                if summary:
                    compressed.append({
                        "role": "system",
                        "content": f"ä»¥ä¸‹æ˜¯ä¹‹å‰å¯¹è¯çš„æ‘˜è¦ï¼š\n\n{summary}"
                    })
            else:
                # è½»åº¦/ä¸­åº¦å‹ç¼©ï¼šè·³è¿‡éƒ¨åˆ†æ¶ˆæ¯
                if compression_level == CompressionLevel.MEDIUM:
                    # ä¿ç•™ä¸­é—´çš„ä¸€åŠ
                    skip_count = len(middle_messages) // 2
                    middle_keep = middle_messages[::skip_count + 1]
                    compressed.extend(middle_keep)
                else:  # LIGHT
                    # ä¿ç•™ä¸­é—´çš„ 75%
                    step = max(1, len(middle_messages) // (keep_middle // 2))
                    compressed.extend(middle_messages[::step])

        # æ·»åŠ æœ€åçš„å¯¹è¯
        if keep_last > 0:
            compressed.extend(non_system_messages[-keep_last:])

        print(f"   - å‹ç¼©åæ¶ˆæ¯æ•°: {len(compressed)}")
        print(f"   - å‹ç¼©ç‡: {(1 - len(compressed)/len(messages)) * 100:.1f}%")

        return compressed

    def _determine_compression_level(
        self,
        messages: List[Dict[str, Any]],
        model: str
    ) -> CompressionLevel:
        """æ ¹æ® token ä½¿ç”¨é‡ç¡®å®šå‹ç¼©çº§åˆ«"""
        info = self.token_counter.get_compression_info(messages, model)
        usage = info["usage_percentage"]

        if usage >= self.MUST_COMPRESS_THRESHOLD:
            return CompressionLevel.AGGRESSIVE
        elif usage >= self.SHOULD_COMPRESS_THRESHOLD:
            return CompressionLevel.MEDIUM
        else:
            return CompressionLevel.LIGHT

    async def _summarize_messages(
        self,
        messages: List[Dict[str, Any]],
        ai_config: Dict[str, Any]
    ) -> Optional[str]:
        """
        ä½¿ç”¨ AI æ€»ç»“æ¶ˆæ¯

        å‚è€ƒ Cline çš„ SummarizeTask å·¥å…·å®ç°
        """
        try:
            # æ„å»ºæ€»ç»“æç¤ºè¯
            summarize_prompt = self._build_summarize_prompt()

            # å°†æ¶ˆæ¯è½¬æ¢ä¸ºæ–‡æœ¬
            messages_text = self._format_messages_for_summary(messages)

            # è°ƒç”¨ AI
            response = await self.ai_manager.chat(
                provider=ai_config.get("ai_provider", "deepseek"),
                model=ai_config.get("ai_model", "deepseek-chat"),
                messages=[{
                    "role": "user",
                    "content": f"{summarize_prompt}\n\nå¯¹è¯å†å²ï¼š\n{messages_text}"
                }],
                api_key=ai_config.get("ai_api_key"),
                base_url=ai_config.get("ai_base_url"),
                temperature=0.3,
                max_tokens=2000
            )

            if response and response.get("content"):
                return response["content"].strip()

        except Exception as e:
            logger.error(f"AI æ€»ç»“å¤±è´¥: {e}")

        return None

    def _build_summarize_prompt(self) -> str:
        """æ„å»ºæ€»ç»“æç¤ºè¯ï¼ˆå‚è€ƒ Cline çš„ summarizeTaskï¼‰"""
        return """è¯·è¯¦ç»†æ€»ç»“ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

1. **ç”¨æˆ·çš„ä¸»è¦è¯·æ±‚**: ç”¨æˆ·æƒ³è¦å®Œæˆä»€ä¹ˆä»»åŠ¡ï¼Ÿ

2. **æŠ€æœ¯æ¦‚å¿µ**: è®¨è®ºäº†å“ªäº›æŠ€æœ¯æ¦‚å¿µã€æ¡†æ¶æˆ–å·¥å…·ï¼Ÿ

3. **å…³é”®æ–‡ä»¶**: æŸ¥çœ‹æˆ–ä¿®æ”¹äº†å“ªäº›æ–‡ä»¶ï¼Ÿï¼ˆåˆ—å‡ºæ–‡ä»¶è·¯å¾„ï¼‰

4. **é—®é¢˜è§£å†³**: è§£å†³äº†å“ªäº›é—®é¢˜ï¼Ÿå¦‚ä½•è§£å†³çš„ï¼Ÿ

5. **å½“å‰çŠ¶æ€**: ç›®å‰ä»»åŠ¡è¿›è¡Œåˆ°å“ªä¸€æ­¥äº†ï¼Ÿ

6. **å¾…åŠäº‹é¡¹**: è¿˜æœ‰å“ªäº›æœªå®Œæˆçš„ä»»åŠ¡ï¼Ÿ

è¯·ç®€æ´ä½†å®Œæ•´åœ°æ€»ç»“ï¼Œä¾¿äºç»§ç»­å®Œæˆä»»åŠ¡ã€‚"""

    def _format_messages_for_summary(self, messages: List[Dict[str, Any]]) -> str:
        """å°†æ¶ˆæ¯æ ¼å¼åŒ–ä¸ºé€‚åˆæ€»ç»“çš„æ–‡æœ¬"""
        parts = []
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")

            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            if len(content) > 500:
                content = content[:500] + "...(å†…å®¹å·²æˆªæ–­)"

            parts.append(f"{role.upper()}: {content}")

        return "\n\n".join(parts)

    def truncate_tool_result(self, tool_name: str, result: Any, max_chars: int = 5000) -> str:
        """
        æˆªæ–­è¿‡é•¿çš„å·¥å…·ç»“æœ

        å‚è€ƒ Cline çš„ç»ˆç«¯è¾“å‡ºæˆªæ–­é€»è¾‘
        """
        result_str = str(result)

        if len(result_str) <= max_chars:
            return result_str

        # ä¿ç•™å‰åŠéƒ¨åˆ†å’ŒååŠéƒ¨åˆ†
        half = max_chars // 2
        truncated = f"{result_str[:half]}\n\n... (ç»“æœå·²æˆªæ–­ï¼ŒåŸé•¿åº¦: {len(result_str)} å­—ç¬¦) ...\n\n{result_str[-half:]}"

        return truncated

    def optimize_file_reads(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä¼˜åŒ–æ–‡ä»¶è¯»å–æ¶ˆæ¯

        å‚è€ƒ Cline çš„æ–‡ä»¶è¯»å–ä¼˜åŒ–ï¼š
        1. è¯†åˆ«é‡å¤çš„æ–‡ä»¶è¯»å–
        2. å°†é‡å¤çš„è¯»å–æ›¿æ¢ä¸ºå¼•ç”¨
        """
        # TODO: å®ç°æ–‡ä»¶è¯»å–ä¼˜åŒ–
        # è¿™éœ€è¦è§£æå·¥å…·è°ƒç”¨ç»“æœï¼Œè¯†åˆ« file_content å—
        return messages

    def get_compression_stats(
        self,
        original: List[Dict[str, Any]],
        compressed: List[Dict[str, Any]],
        model: str
    ) -> Dict[str, Any]:
        """è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯"""
        original_tokens = self.token_counter.count_messages_tokens(original)
        compressed_tokens = self.token_counter.count_messages_tokens(compressed)

        return {
            "original_messages": len(original),
            "compressed_messages": len(compressed),
            "original_tokens": original_tokens,
            "compressed_tokens": compressed_tokens,
            "tokens_saved": original_tokens - compressed_tokens,
            "compression_ratio": (1 - compressed_tokens / original_tokens) if original_tokens > 0 else 0,
            "context_window": self.token_counter.get_context_window(model),
            "max_allowed": self.token_counter.get_max_allowed_size(model),
        }
