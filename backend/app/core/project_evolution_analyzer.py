import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import statistics
from collections import defaultdict
import re
import json
from pathlib import Path
from app.core.ai_manager import AIManager
from app.core.git_manager import GitProject
from app.core.chart_generator import chart_generator

class ProjectEvolutionAnalyzer:
    """é¡¹ç›®æ¼”åŒ–æ—¶é—´çº¿åˆ†æå™¨ - å¸¦æ•°æ®å¯è§†åŒ–"""

    def __init__(self):
        self.ai_manager = AIManager()

    def _load_ai_config(self) -> Dict[str, Any]:
        """åŠ¨æ€åŠ è½½AIé…ç½®æ–‡ä»¶ - æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°è¯»å–"""
        try:
            # ç›´æ¥è¯»å–AIé…ç½®æ–‡ä»¶ - ä»backendç›®å½•å¼€å§‹æŸ¥æ‰¾
            config_path = Path(__file__).parent.parent.parent / "AI-Config.json"

            if not config_path.exists():
                print(f"âš ï¸ AIé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                return self._get_default_ai_config()

            with open(config_path, 'r', encoding='utf-8') as f:
                ai_config = json.load(f)

            # éªŒè¯å¿…è¦çš„é…ç½®å­—æ®µ
            required_fields = ["ai_provider", "ai_model", "ai_api_key"]
            missing_fields = [field for field in required_fields if not ai_config.get(field)]

            if missing_fields:
                print(f"âš ï¸ AIé…ç½®ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                return self._get_default_ai_config()

            print(f"âœ… æˆåŠŸåŠ è½½AIé…ç½®: {ai_config['ai_provider']} - {ai_config['ai_model']}")
            return ai_config

        except json.JSONDecodeError as e:
            print(f"âŒ AIé…ç½®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}")
            return self._get_default_ai_config()
        except Exception as e:
            print(f"âŒ è¯»å–AIé…ç½®å¤±è´¥: {e}")
            return self._get_default_ai_config()

    def _get_default_ai_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤AIé…ç½®"""
        return {
            "ai_provider": "openai",
            "ai_model": "gpt-4o-mini",
            "ai_api_key": "",
            "ai_base_url": None,
            "temperature": 0.7,
            "max_tokens": 2000
        }

    async def generate_evolution_timeline_md(self, project_path: str,
                                           analysis_depth: str = "medium") -> str:
        """ç”Ÿæˆå¸¦æœ‰å›¾ç‰‡åµŒå…¥çš„é¡¹ç›®æ¼”åŒ–æ—¶é—´çº¿Markdownæ–‡æ¡£"""

        print(f"ğŸ” å¼€å§‹åˆ†æé¡¹ç›®æ¼”åŒ–å†å²... é¡¹ç›®è·¯å¾„: {project_path}")

        # 1. è·å–é¡¹ç›®åŸºæœ¬ä¿¡æ¯ - ä½¿ç”¨GitManagerè€Œä¸æ˜¯ç›´æ¥åˆ›å»º
        from app.core.git_manager import GitManager
        git_manager = GitManager()
        project = git_manager.get_project(project_path)

        if not project:
            error_msg = f"é¡¹ç›®æœªæ‰¾åˆ°: {project_path}"
            print(f"âŒ {error_msg}")
            return self._generate_error_report(error_msg)

        if not project.is_valid():
            error_msg = f"æ— æ•ˆçš„Gitä»“åº“: {project_path}"
            print(f"âŒ {error_msg}")
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            from pathlib import Path
            if not Path(project_path).exists():
                error_msg += f" (è·¯å¾„ä¸å­˜åœ¨)"
            else:
                error_msg += f" (è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯Gitä»“åº“)"
            return self._generate_error_report(error_msg)

        project_info = project.get_info()

        # 2. è·å–æäº¤å†å²
        commits = await self._get_commit_history(project, analysis_depth)
        if not commits:
            return self._generate_error_report("æ— æ³•è·å–æäº¤å†å²")

        # 3. åˆ†ææ—¶é—´çº¿æ•°æ®
        timeline_data = await self._analyze_timeline_data(commits)

        # 4. åˆ†æè´¡çŒ®è€…æ•°æ®
        contributor_data = await self._analyze_contributor_activity(commits)

        # 5. ç”ŸæˆAIæ´å¯Ÿ
        ai_insights = await self._generate_ai_insights(timeline_data, contributor_data)

        # 6. ç”Ÿæˆå®Œæ•´Markdownæ–‡æ¡£ï¼ˆçº¯æ–‡æœ¬ç‰ˆæœ¬ï¼‰
        markdown_content = self._generate_text_markdown_report(
            project_info, timeline_data, contributor_data, ai_insights, len(commits)
        )

        # 8. ä¿å­˜æ–‡æ¡£
        doc_path = self._save_evolution_document(project_path, markdown_content)

        return markdown_content

    def _generate_error_report(self, error_msg: str) -> str:
        """ç”Ÿæˆé”™è¯¯æŠ¥å‘Š"""
        return f"""# âŒ é¡¹ç›®æ¼”åŒ–æ—¶é—´çº¿åˆ†æå¤±è´¥

## é”™è¯¯ä¿¡æ¯
{error_msg}

## å¯èƒ½çš„åŸå› 
- é¡¹ç›®ä¸æ˜¯æœ‰æ•ˆçš„Gitä»“åº“
- æ²¡æœ‰æäº¤å†å²
- æ–‡ä»¶æƒé™é—®é¢˜

---
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    async def _get_commit_history(self, project: GitProject, depth: str) -> List[Dict[str, Any]]:
        """è·å–æäº¤å†å²"""
        max_commits = {"light": 100, "medium": 500, "full": 2000}.get(depth, 500)

        commits = []
        try:
            for commit in project.repo.iter_commits(max_count=max_commits):
                commit_data = {
                    "hash": str(commit.hexsha),
                    "message": commit.message.strip(),
                    "author": str(commit.author),
                    "email": commit.author.email,
                    "date": commit.committed_datetime.isoformat(),
                    "stats": {"insertions": 0, "deletions": 0, "lines": 0},
                    "files_changed": []
                }

                # è·å–ç»Ÿè®¡ä¿¡æ¯
                if hasattr(commit, 'stats') and commit.stats.total:
                    commit_data["stats"] = {
                        "insertions": commit.stats.total.get("insertions", 0),
                        "deletions": commit.stats.total.get("deletions", 0),
                        "lines": commit.stats.total.get("lines", 0)
                    }
                    commit_data["files_changed"] = list(commit.stats.files.keys())

                commits.append(commit_data)

        except Exception as e:
            print(f"è·å–æäº¤å†å²å¤±è´¥: {e}")

        return commits

    async def _analyze_timeline_data(self, commits: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†ææ—¶é—´çº¿æ•°æ®"""

        # æŒ‰æœˆä»½åˆ†ç»„
        monthly_stats = defaultdict(lambda: {
            "commits": 0, "insertions": 0, "deletions": 0,
            "authors": set(), "file_types": defaultdict(int)
        })

        for commit in commits:
            date = datetime.fromisoformat(commit["date"])
            month_key = f"{date.year}-{date.month:02d}"

            monthly_stats[month_key]["commits"] += 1
            monthly_stats[month_key]["insertions"] += commit["stats"].get("insertions", 0)
            monthly_stats[month_key]["deletions"] += commit["stats"].get("deletions", 0)
            monthly_stats[month_key]["authors"].add(commit["author"])

            # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
            for file_path in commit["files_changed"]:
                ext = file_path.split('.')[-1] if '.' in file_path else 'other'
                monthly_stats[month_key]["file_types"][ext] += 1

        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        timeline = []
        for month, stats in sorted(monthly_stats.items()):
            timeline.append({
                "month": month,
                "commits": stats["commits"],
                "lines_changed": stats["insertions"] + stats["deletions"],
                "active_contributors": len(stats["authors"]),
                "file_types": dict(stats["file_types"])
            })

        return {
            "timeline": timeline,
            "total_months": len(timeline),
            "avg_commits_per_month": round(statistics.mean([m["commits"] for m in timeline]), 1) if timeline else 0,
            "most_active_month": max(timeline, key=lambda x: x["commits"]) if timeline else None,
            "total_lines_changed": sum([m["lines_changed"] for m in timeline])
        }

    async def _analyze_contributor_activity(self, commits: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æè´¡çŒ®è€…æ´»è·ƒåº¦"""

        contributor_stats = defaultdict(lambda: {
            "total_commits": 0,
            "first_commit": None,
            "last_commit": None,
            "lines_changed": 0,
            "file_types": defaultdict(int),
            "monthly_activity": defaultdict(int)
        })

        for commit in commits:
            author = commit["author"]
            date = datetime.fromisoformat(commit["date"])
            month_key = f"{date.year}-{date.month:02d}"

            contributor_stats[author]["total_commits"] += 1
            contributor_stats[author]["lines_changed"] += (
                commit["stats"].get("insertions", 0) + commit["stats"].get("deletions", 0)
            )
            contributor_stats[author]["monthly_activity"][month_key] += 1

            # æ›´æ–°æ—¶é—´èŒƒå›´
            if contributor_stats[author]["first_commit"] is None:
                contributor_stats[author]["first_commit"] = commit["date"]
            contributor_stats[author]["last_commit"] = commit["date"]

            # ç»Ÿè®¡æ–‡ä»¶ç±»å‹åå¥½
            for file_path in commit["files_changed"]:
                ext = file_path.split('.')[-1] if '.' in file_path else 'other'
                contributor_stats[author]["file_types"][ext] += 1

        # æ’åºè´¡çŒ®è€…
        top_contributors = sorted(
            contributor_stats.items(),
            key=lambda x: x[1]["lines_changed"],
            reverse=True
        )[:10]

        return {
            "contributor_stats": dict(contributor_stats),
            "top_contributors": top_contributors,
            "total_contributors": len(contributor_stats)
        }

    async def _generate_image_charts(self, timeline_data: Dict[str, Any],
                                   contributor_data: Dict[str, Any],
                                   project_path: str) -> Dict[str, str]:
        """ç”Ÿæˆå›¾ç‰‡å›¾è¡¨å¹¶è¿”å›å›¾ç‰‡è·¯å¾„"""

        # è®¾ç½®assetsç›®å½•
        chart_generator.setup_assets_dir(project_path)

        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        return chart_generator.generate_all_charts(timeline_data, contributor_data)

    async def _generate_ai_insights(self, timeline_data: Dict[str, Any],
                                  contributor_data: Dict[str, Any]) -> str:
        """ç”ŸæˆAIæ´å¯Ÿåˆ†æ - åŠ¨æ€è¯»å–é…ç½®"""

        # æ„å»ºAIåˆ†ææç¤ºè¯
        prompt = f"""
åŸºäºä»¥ä¸‹é¡¹ç›®æ•°æ®ï¼Œæä¾›é¡¹ç›®æ¼”åŒ–è¶‹åŠ¿çš„ä¸“ä¸šåˆ†æï¼š

ğŸ“Š æ—¶é—´çº¿æ•°æ®:
- æ€»æœˆä»½æ•°: {timeline_data['total_months']}
- æœˆå‡æäº¤æ•°: {timeline_data['avg_commits_per_month']}
- æœ€æ´»è·ƒæœˆä»½: {timeline_data['most_active_month']['month'] if timeline_data['most_active_month'] else 'æ— '}
- æ€»ä»£ç å˜æ›´: {timeline_data['total_lines_changed']:,} è¡Œ

ğŸ‘¥ è´¡çŒ®è€…æ•°æ®:
- æ€»è´¡çŒ®è€…æ•°: {contributor_data['total_contributors']}
- Topè´¡çŒ®è€…: {', '.join([f"{name}({stats['total_commits']}æ¬¡)" for name, stats in contributor_data['top_contributors'][:3]])}

è¯·ä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œæ·±åº¦åˆ†æï¼š
1. é¡¹ç›®å‘å±•é˜¶æ®µè¯„ä¼°ï¼ˆèŒèŠ½æœŸ/æˆé•¿æœŸ/æˆç†ŸæœŸ/ç»´æŠ¤æœŸï¼‰
2. å›¢é˜Ÿåä½œæ¨¡å¼åˆ†æ
3. æŠ€æœ¯æ ˆæ¼”åŒ–è¶‹åŠ¿
4. é¡¹ç›®å¥åº·åº¦è¯„ä¼°
5. æœªæ¥å‘å±•å»ºè®®

è¯·ç”¨ä¸“ä¸šã€æ•°æ®é©±åŠ¨çš„è¯­è¨€è¿›è¡Œåˆ†æï¼ŒåŒ…å«å…·ä½“çš„æŒ‡æ ‡å’Œè¶‹åŠ¿åˆ¤æ–­ã€‚
"""

        try:
            # ğŸ”„ æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°è¯»å–AIé…ç½®
            ai_config = self._load_ai_config()

            print(f"ğŸ¤– ä½¿ç”¨AIé…ç½®: {ai_config['ai_provider']} - {ai_config['ai_model']}")

            # ä½¿ç”¨ç±»ä¸­å·²åˆå§‹åŒ–çš„AIç®¡ç†å™¨å®ä¾‹
            response = await self.ai_manager.chat(
                provider=ai_config["ai_provider"],
                model=ai_config["ai_model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é¡¹ç›®åˆ†æå¸ˆï¼Œæ“…é•¿ä»Gitå†å²æ•°æ®ä¸­æå–æ´å¯Ÿå¹¶é¢„æµ‹å‘å±•è¶‹åŠ¿ã€‚è¯·ç”¨ä¸“ä¸šã€æ•°æ®é©±åŠ¨çš„æ–¹å¼è¿›è¡Œåˆ†æã€‚"},
                    {"role": "user", "content": prompt}
                ],
                api_key=ai_config["ai_api_key"],
                base_url=ai_config.get("ai_base_url"),
                temperature=ai_config.get("temperature", 0.7),
                max_tokens=ai_config.get("max_tokens", 1500)
            )

            print("âœ… AIæ´å¯Ÿåˆ†æå®Œæˆ")
            return response["content"]

        except Exception as e:
            error_msg = f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨: {str(e)}"
            print(f"âŒ AIæ´å¯Ÿåˆ†æå¤±è´¥: {e}")
            return error_msg

    def _generate_visual_markdown_report(self, project_info: Dict[str, Any],
                                       timeline_data: Dict[str, Any],
                                       contributor_data: Dict[str, Any],
                                       charts: Dict[str, str],
                                       ai_insights: str,
                                       total_commits: int) -> str:
        """ç”Ÿæˆå¸¦æœ‰å›¾ç‰‡åµŒå…¥çš„MarkdownæŠ¥å‘Š"""

        # è·å–å½“å‰AIé…ç½®ä¿¡æ¯ç”¨äºæŠ¥å‘Šæ˜¾ç¤º
        ai_config = self._load_ai_config()

        report = f"""# ğŸ“Š é¡¹ç›®æ¼”åŒ–æ—¶é—´çº¿åˆ†ææŠ¥å‘Š

## ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ

- **é¡¹ç›®åç§°**: {project_info.get('name', 'Unknown')}
- **Gitä»“åº“**: {project_info.get('remote_url', 'æœ¬åœ°ä»“åº“')}
- **å½“å‰åˆ†æ”¯**: {project_info.get('current_branch', 'main')}
- **æ€»æäº¤æ•°**: {total_commits:,}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“ˆ æ—¶é—´çº¿ç»Ÿè®¡

### æœˆåº¦æ´»è·ƒåº¦æ¦‚è§ˆ

| æœˆä»½ | æäº¤æ•° | ä»£ç å˜æ›´ | æ´»è·ƒè´¡çŒ®è€… |
|------|--------|----------|------------|
"""

        # æ·»åŠ æ—¶é—´çº¿è¡¨æ ¼ï¼ˆæœ€è¿‘12ä¸ªæœˆï¼‰
        for item in timeline_data["timeline"][-12:]:
            report += f"| {item['month']} | {item['commits']} | {item['lines_changed']:,} | {item['active_contributors']} |\n"

        report += f"""

### ğŸ“Š å…³é”®æŒ‡æ ‡

- ğŸ“… **æ´»è·ƒæœˆä»½**: {timeline_data['total_months']} ä¸ªæœˆ
- ğŸš€ **æœˆå‡æäº¤**: {timeline_data['avg_commits_per_month']} æ¬¡/æœˆ
- ğŸ‘¥ **è´¡çŒ®è€…æ€»æ•°**: {contributor_data['total_contributors']} äºº
- ğŸ† **æœ€æ´»è·ƒæœˆä»½**: {timeline_data['most_active_month']['month'] if timeline_data['most_active_month'] else 'æ— æ•°æ®'}
- ğŸ“ **æ€»ä»£ç å˜æ›´**: {timeline_data['total_lines_changed']:,} è¡Œ

---

## ğŸ“Š æ•°æ®å¯è§†åŒ–å›¾è¡¨

### æäº¤æ´»è·ƒåº¦æ—¶é—´çº¿
![æäº¤æ´»è·ƒåº¦æ—¶é—´çº¿]({charts['commit_timeline']})

### è´¡çŒ®è€…æ´»è·ƒåº¦æ’å
![è´¡çŒ®è€…æ´»è·ƒåº¦æ’å]({charts['contributor_chart']})

### æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
![æ–‡ä»¶ç±»å‹åˆ†å¸ƒ]({charts['file_type_chart']})

### æœˆåº¦æ´»è·ƒåº¦çƒ­åŠ›å›¾
![æœˆåº¦æ´»è·ƒåº¦çƒ­åŠ›å›¾]({charts['activity_heatmap']})

---

## ğŸ‘¥ è´¡çŒ®è€…æ·±åº¦åˆ†æ

### Top 10 è´¡çŒ®è€…è¯¦ç»†æ•°æ®

| æ’å | è´¡çŒ®è€… | æäº¤æ•° | ä»£ç å˜æ›´ | ä¸»è¦æ–‡ä»¶ç±»å‹ | è´¡çŒ®æ—¶é•¿ |
|------|--------|--------|----------|--------------|----------|
"""

        # æ·»åŠ è´¡çŒ®è€…è¯¦ç»†è¡¨æ ¼
        for i, (name, stats) in enumerate(contributor_data['top_contributors'][:10], 1):
            top_file_type = max(stats['file_types'].items(), key=lambda x: x[1]) if stats['file_types'] else ('æ— ', 0)

            # è®¡ç®—è´¡çŒ®æ—¶é•¿
            if stats['first_commit'] and stats['last_commit']:
                first_date = datetime.fromisoformat(stats['first_commit'])
                last_date = datetime.fromisoformat(stats['last_commit'])
                duration_days = (last_date - first_date).days
                duration_str = f"{duration_days}å¤©" if duration_days > 0 else "å•æ¬¡"
            else:
                duration_str = "æœªçŸ¥"

            report += f"| {i} | {name} | {stats['total_commits']} | {stats['lines_changed']:,} | {top_file_type[0]} | {duration_str} |\n"

        report += f"""

---

## ğŸ” AIæ™ºèƒ½æ´å¯Ÿåˆ†æ

{ai_insights}

---

## ğŸ“‹ æŠ€æœ¯æ ˆæ¼”åŒ–è¶‹åŠ¿

### æ–‡ä»¶ç±»å‹å˜æ›´ç»Ÿè®¡

"""

        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
        file_type_totals = defaultdict(int)
        for item in timeline_data["timeline"]:
            for ext, count in item["file_types"].items():
                file_type_totals[ext] += count

        # ç”Ÿæˆæ–‡ä»¶ç±»å‹ç»Ÿè®¡
        for ext, count in sorted(file_type_totals.items(), key=lambda x: x[1], reverse=True)[:10]:
            percentage = (count / sum(file_type_totals.values())) * 100
            report += f"- **{ext}**: {count:,} æ¬¡å˜æ›´ ({percentage:.1f}%)\n"

        report += f"""

---

## ğŸ¯ é¡¹ç›®å¥åº·åº¦è¯„ä¼°

### å¥åº·åº¦é›·è¾¾å›¾
![é¡¹ç›®å¥åº·åº¦é›·è¾¾å›¾]({charts['health_radar']})

### å¥åº·åº¦è¯„åˆ†è¯¦æƒ…
"""

        # è®¡ç®—å„é¡¹è¯„åˆ†
        activity_score = chart_generator._calculate_activity_score(timeline_data)
        diversity_score = chart_generator._calculate_diversity_score(contributor_data)
        maturity_score = chart_generator._calculate_maturity_score(timeline_data, total_commits)

        report += f"""
- **æ´»è·ƒåº¦è¯„åˆ†**: {activity_score}/100
- **è´¡çŒ®è€…å¤šæ ·æ€§**: {diversity_score}/100
- **é¡¹ç›®æˆç†Ÿåº¦**: {maturity_score}/100

---

*ğŸ“Š æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*ğŸ” åˆ†ææäº¤æ•°: {total_commits:,}*
*ğŸ“ˆ åˆ†ææ·±åº¦: æœ€è¿‘{timeline_data['total_months']}ä¸ªæœˆ*
*ğŸ¤– AIåˆ†ææä¾›å•†: {ai_config.get('ai_provider', 'Unknown')} ({ai_config.get('ai_model', 'Unknown')})*

---

"""

        return report

    def _generate_text_markdown_report(self, project_info: Dict[str, Any],
                                      timeline_data: Dict[str, Any],
                                      contributor_data: Dict[str, Any],
                                      ai_insights: str,
                                      total_commits: int) -> str:
        """ç”Ÿæˆçº¯æ–‡æœ¬MarkdownæŠ¥å‘Šï¼ˆä¸åŒ…å«å›¾ç‰‡ï¼‰"""

        # è·å–å½“å‰AIé…ç½®ä¿¡æ¯ç”¨äºæŠ¥å‘Šæ˜¾ç¤º
        ai_config = self._load_ai_config()

        report = f"""# ğŸ“Š é¡¹ç›®æ¼”åŒ–æ—¶é—´çº¿åˆ†ææŠ¥å‘Š

## ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ

- **é¡¹ç›®åç§°**: {project_info.get('name', 'Unknown')}
- **Gitä»“åº“**: {project_info.get('remote_url', 'æœ¬åœ°ä»“åº“')}
- **å½“å‰åˆ†æ”¯**: {project_info.get('current_branch', 'main')}
- **æ€»æäº¤æ•°**: {total_commits:,}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“ˆ æ—¶é—´çº¿ç»Ÿè®¡

### æœˆåº¦æ´»è·ƒåº¦æ¦‚è§ˆ

| æœˆä»½ | æäº¤æ•° | ä»£ç å˜æ›´ | æ´»è·ƒè´¡çŒ®è€… |
|------|--------|----------|------------|
"""

        # æ·»åŠ æ—¶é—´çº¿è¡¨æ ¼ï¼ˆæœ€è¿‘12ä¸ªæœˆï¼‰
        for item in timeline_data["timeline"][-12:]:
            report += f"| {item['month']} | {item['commits']} | {item['lines_changed']:,} | {item['active_contributors']} |\n"

        report += f"""

### ğŸ“Š å…³é”®æŒ‡æ ‡

- ğŸ“… **æ´»è·ƒæœˆä»½**: {timeline_data['total_months']} ä¸ªæœˆ
- ğŸš€ **æœˆå‡æäº¤**: {timeline_data['avg_commits_per_month']} æ¬¡/æœˆ
- ğŸ‘¥ **è´¡çŒ®è€…æ€»æ•°**: {contributor_data['total_contributors']} äºº
- ğŸ† **æœ€æ´»è·ƒæœˆä»½**: {timeline_data['most_active_month']['month'] if timeline_data['most_active_month'] else 'æ— æ•°æ®'}
- ğŸ“ **æ€»ä»£ç å˜æ›´**: {timeline_data['total_lines_changed']:,} è¡Œ

---

## ğŸ“Š æ•°æ®å¯è§†åŒ–ï¼ˆæ–‡æœ¬å½¢å¼ï¼‰

### æäº¤æ´»è·ƒåº¦æ—¶é—´çº¿
```
"""

        # ç”Ÿæˆç®€å•çš„æ–‡æœ¬å›¾è¡¨
        max_commits = max([item['commits'] for item in timeline_data["timeline"]], default=0)
        for item in timeline_data["timeline"][-12:]:
            bar_length = int((item['commits'] / max_commits) * 20) if max_commits > 0 else 0
            bar = "â–ˆ" * bar_length
            report += f"{item['month']}: {bar} ({item['commits']}æ¬¡)\n"

        report += f"""```

### è´¡çŒ®è€…æ´»è·ƒåº¦æ’å
"""

        # ç”Ÿæˆè´¡çŒ®è€…æ’åæ–‡æœ¬
        for i, (name, stats) in enumerate(contributor_data['top_contributors'][:10], 1):
            bar_length = int((stats['lines_changed'] / contributor_data['top_contributors'][0][1]['lines_changed']) * 20) if contributor_data['top_contributors'] else 0
            bar = "â–ˆ" * bar_length
            report += f"{i}. {name}: {bar} ({stats['lines_changed']:,}è¡Œ)\n"

        report += f"""

### æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
"""

        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
        file_type_totals = defaultdict(int)
        for item in timeline_data["timeline"]:
            for ext, count in item["file_types"].items():
                file_type_totals[ext] += count

        # ç”Ÿæˆæ–‡ä»¶ç±»å‹æ–‡æœ¬å›¾è¡¨
        max_count = max(file_type_totals.values(), default=0)
        for ext, count in sorted(file_type_totals.items(), key=lambda x: x[1], reverse=True)[:10]:
            percentage = (count / sum(file_type_totals.values())) * 100 if file_type_totals else 0
            bar_length = int((count / max_count) * 20) if max_count > 0 else 0
            bar = "â–ˆ" * bar_length
            report += f"{ext.upper()}: {bar} ({count:,}æ¬¡, {percentage:.1f}%)\n"

        report += f"""

---

## ğŸ‘¥ è´¡çŒ®è€…æ·±åº¦åˆ†æ

### Top 10 è´¡çŒ®è€…è¯¦ç»†æ•°æ®

| æ’å | è´¡çŒ®è€… | æäº¤æ•° | ä»£ç å˜æ›´ | ä¸»è¦æ–‡ä»¶ç±»å‹ | è´¡çŒ®æ—¶é•¿ |
|------|--------|--------|----------|--------------|----------|
"""

        # æ·»åŠ è´¡çŒ®è€…è¯¦ç»†è¡¨æ ¼
        for i, (name, stats) in enumerate(contributor_data['top_contributors'][:10], 1):
            top_file_type = max(stats['file_types'].items(), key=lambda x: x[1]) if stats['file_types'] else ('æ— ', 0)

            # è®¡ç®—è´¡çŒ®æ—¶é•¿
            if stats['first_commit'] and stats['last_commit']:
                first_date = datetime.fromisoformat(stats['first_commit'])
                last_date = datetime.fromisoformat(stats['last_commit'])
                duration_days = (last_date - first_date).days
                duration_str = f"{duration_days}å¤©" if duration_days > 0 else "å•æ¬¡"
            else:
                duration_str = "æœªçŸ¥"

            report += f"| {i} | {name} | {stats['total_commits']} | {stats['lines_changed']:,} | {top_file_type[0]} | {duration_str} |\n"

        report += f"""

---

## ğŸ” AIæ™ºèƒ½æ´å¯Ÿåˆ†æ

{ai_insights}

---

## ğŸ“‹ æŠ€æœ¯æ ˆæ¼”åŒ–è¶‹åŠ¿

### æ–‡ä»¶ç±»å‹å˜æ›´ç»Ÿè®¡

"""

        # ç”Ÿæˆæ–‡ä»¶ç±»å‹ç»Ÿè®¡
        for ext, count in sorted(file_type_totals.items(), key=lambda x: x[1], reverse=True)[:10]:
            percentage = (count / sum(file_type_totals.values())) * 100 if file_type_totals else 0
            report += f"- **{ext}**: {count:,} æ¬¡å˜æ›´ ({percentage:.1f}%)\n"

        report += f"""

---

## ğŸ¯ é¡¹ç›®å¥åº·åº¦è¯„ä¼°

### å¥åº·åº¦è¯„åˆ†è¯¦æƒ…
"""

        # è®¡ç®—å„é¡¹è¯„åˆ†ï¼ˆä½¿ç”¨ç®€å•çš„è®¡ç®—æ–¹æ³•ï¼‰
        activity_score = min(100, int(timeline_data['avg_commits_per_month'] * 5))
        diversity_score = min(100, int(contributor_data['total_contributors'] * 8))
        maturity_score = min(100, int((timeline_data['total_months'] * 2) + (timeline_data['avg_commits_per_month'] * 3)))

        report += f"""
- **æ´»è·ƒåº¦è¯„åˆ†**: {activity_score}/100
- **è´¡çŒ®è€…å¤šæ ·æ€§**: {diversity_score}/100
- **é¡¹ç›®æˆç†Ÿåº¦**: {maturity_score}/100

---

*ğŸ“Š æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*ğŸ” åˆ†ææäº¤æ•°: {total_commits:,}*
*ğŸ“ˆ åˆ†ææ·±åº¦: æœ€è¿‘{timeline_data['total_months']}ä¸ªæœˆ*
*ğŸ¤– AIåˆ†ææä¾›å•†: {ai_config.get('ai_provider', 'Unknown')} ({ai_config.get('ai_model', 'Unknown')})*

---

"""

        return report

    def _save_evolution_document(self, project_path: str, content: str) -> str:
        """ä¿å­˜æ¼”åŒ–åˆ†ææ–‡æ¡£"""

        # åˆ›å»ºæ–‡æ¡£ç›®å½•
        docs_dir = Path(project_path) / "git-ai-docs"
        docs_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"evolution_timeline_{timestamp}.md"
        file_path = docs_dir / filename

        # ä¿å­˜æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"âœ… æ¼”åŒ–æ—¶é—´çº¿æ–‡æ¡£å·²ä¿å­˜: {file_path}")
        return str(file_path)

# åˆ›å»ºå…¨å±€å®ä¾‹
project_evolution_analyzer = ProjectEvolutionAnalyzer()
