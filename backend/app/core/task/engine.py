"""
ä»»åŠ¡æ‰§è¡Œå¼•æ“ - å€Ÿé‰´ Cline çš„é€’å½’ä»»åŠ¡å¾ªç¯æ¶æ„

è¿™æ˜¯æ ¸å¿ƒçš„ä»»åŠ¡æ‰§è¡Œå™¨ï¼Œè´Ÿè´£ï¼š
1. å¯åŠ¨ä»»åŠ¡
2. é€’å½’ä»»åŠ¡å¾ªç¯
3. å·¥å…·è°ƒç”¨ç®¡ç†
4. é”™è¯¯å¤„ç†å’Œé‡è¯•
"""

import json
import logging
import uuid
from typing import Dict, Any, List, Optional, AsyncIterator
from datetime import datetime

from app.core.ai_manager import AIManager
from app.core.tools import (
    ToolCoordinator,
    ToolCall,
    ToolContext,
    get_tool_coordinator
)
from app.core.task.task_state import TaskState
from app.core.task.tools_converter import tools_to_openai_functions, parse_tool_call_arguments
from app.core.task.prompt_builder import PromptBuilder
from app.core.context import TokenCounter, CompressionStrategy


logger = logging.getLogger(__name__)


class TaskEngine:
    """
    ä»»åŠ¡æ‰§è¡Œå¼•æ“ - Git AI Core çš„æ ¸å¿ƒ

    ç±»ä¼¼ Cline çš„ Task ç±»ï¼Œå®ç°é€’å½’ä»»åŠ¡å¾ªç¯
    """

    def __init__(
        self,
        ai_manager: Optional[AIManager] = None,
        tool_coordinator: Optional[ToolCoordinator] = None,
        max_iterations: int = 999,  # å–æ¶ˆè¿­ä»£é™åˆ¶ï¼Œè®¾ç½®ä¸ºå¾ˆå¤§çš„å€¼
        max_consecutive_mistakes: int = 3
    ):
        self.ai_manager = ai_manager or AIManager()
        self.tool_coordinator = tool_coordinator or get_tool_coordinator()
        self.prompt_builder = PromptBuilder(self.tool_coordinator)
        self.tools_definition = tools_to_openai_functions(self.tool_coordinator)

        # ä¸Šä¸‹æ–‡ç®¡ç†
        self.token_counter = TokenCounter()
        self.compression_strategy = CompressionStrategy(self.ai_manager)

        # é…ç½®
        self.max_iterations = max_iterations
        self.max_consecutive_mistakes = max_consecutive_mistakes

        # ä»»åŠ¡çŠ¶æ€
        self.task_state = TaskState()
        self.conversation_history = []

    async def execute_task(
        self,
        user_input: str,
        repository_path: str,
        ai_config: Dict[str, Any]
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        æ‰§è¡Œä»»åŠ¡ - ä¸»å…¥å£ç‚¹

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            repository_path: Git ä»“åº“è·¯å¾„
            ai_config: AI é…ç½®

        Yields:
            ä»»åŠ¡è¿›åº¦ä¿¡æ¯ï¼ˆç”¨äºæµå¼å“åº”ï¼‰
        """
        print("\n" + "="*80)
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡")
        print("="*80)
        print(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
        print(f"ğŸ“ ä»“åº“è·¯å¾„: {repository_path}")
        print(f"ğŸ¤– AI é…ç½®: {ai_config.get('ai_provider')} - {ai_config.get('ai_model')}")
        print("="*80 + "\n")

        logger.info(f"=== å¼€å§‹ä»»åŠ¡ ===")
        logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
        logger.info(f"ä»“åº“è·¯å¾„: {repository_path}")

        # 1. åˆå§‹åŒ–
        self.task_state.reset_for_new_task()
        context = ToolContext(
            repository_path=repository_path,
            conversation_history=[],
            metadata={"ai_config": ai_config}
        )

        # 2. æ„å»ºåˆå§‹ç”¨æˆ·æ¶ˆæ¯
        user_content = [{
            "type": "text",
            "text": f"<task>\n{user_input}\n</task>"
        }]

        # 3. å¯åŠ¨ä»»åŠ¡å¾ªç¯
        try:
            async for event in self._task_loop(user_content, context, ai_config):
                yield event
        except Exception as e:
            print(f"\n{'='*80}")
            print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            print(f"{'='*80}\n")
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield {
                "type": "error",
                "message": f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            }

        print("\n" + "="*80)
        print("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
        print("="*80 + "\n")

        logger.info(f"=== ä»»åŠ¡ç»“æŸ ===")

    async def _task_loop(
        self,
        initial_user_content: List[Dict[str, Any]],
        context: ToolContext,
        ai_config: Dict[str, Any]
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        é€’å½’ä»»åŠ¡å¾ªç¯ - æ ¸å¿ƒé€»è¾‘

        ç±»ä¼¼ Cline çš„ initiateTaskLoop + recursivelyMakeClineRequests
        """
        next_user_content = initial_user_content
        iteration = 0

        while iteration < self.max_iterations:
            iteration += 1

            # æ£€æŸ¥ä¸­æ­¢æ ‡å¿—
            if self.task_state.should_abort():
                print(f"\nâš ï¸  ä»»åŠ¡è¢«ä¸­æ­¢")
                logger.info("ä»»åŠ¡è¢«ä¸­æ­¢")
                yield {
                    "type": "aborted",
                    "iteration": iteration
                }
                break

            # æ£€æŸ¥é”™è¯¯æ¬¡æ•°
            if self.task_state.consecutive_mistake_count >= self.max_consecutive_mistakes:
                print(f"\nâŒ è¾¾åˆ°æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°: {self.task_state.consecutive_mistake_count}")
                logger.error(f"è¾¾åˆ°æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°: {self.task_state.consecutive_mistake_count}")
                yield {
                    "type": "error",
                    "message": f"è¾¾åˆ°æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•° ({self.task_state.consecutive_mistake_count})",
                    "iteration": iteration
                }
                break

            print(f"\n{'â”€'*80}")
            print(f"ğŸ”„ è¿­ä»£ {iteration}/{self.max_iterations}")
            print(f"{'â”€'*80}\n")

            logger.info(f"=== è¿­ä»£ {iteration} ===")

            # æ‰§è¡Œå•æ¬¡è¯·æ±‚
            did_end_loop = False
            async for event in self._execute_single_request(next_user_content, context, ai_config, iteration):
                yield event

                # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                if event.get("type") == "completion":
                    did_end_loop = True
                elif event.get("type") == "error":
                    self.task_state.increment_mistake_count()

            if did_end_loop:
                print(f"\nâœ… ä»»åŠ¡å®Œæˆï¼Œé€€å‡ºå¾ªç¯")
                logger.info("ä»»åŠ¡å®Œæˆ")
                break
            else:
                # ç»§ç»­å¾ªç¯ï¼Œæç¤º AI ä½¿ç”¨å·¥å…·
                next_user_content = [{
                    "type": "text",
                    "text": "è¯·ä½¿ç”¨å·¥å…·æ¥å®Œæˆä»»åŠ¡ï¼Œæˆ–è€…å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ã€‚"
                }]

    async def _execute_single_request(
        self,
        user_content: List[Dict[str, Any]],
        context: ToolContext,
        ai_config: Dict[str, Any],
        iteration: int
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        æ‰§è¡Œå•æ¬¡ API è¯·æ±‚ï¼ˆä½¿ç”¨ Tools APIï¼‰

        ç±»ä¼¼ Cline çš„ attemptApiRequest + å·¥å…·æ‰§è¡Œ
        """
        # 1. æ„å»ºæ¶ˆæ¯å†å²ï¼ˆå¸¦ä¸Šä¸‹æ–‡å‹ç¼©ï¼‰
        messages = await self._build_messages(user_content, ai_config)

        # 2. ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
        system_prompt = await self.prompt_builder.build_prompt(context)

        # 3. è°ƒç”¨ AIï¼ˆä½¿ç”¨ Tools APIï¼‰
        self.task_state.increment_api_request_count()

        print(f"ğŸ“¤ å‘é€ API è¯·æ±‚...")
        print(f"   - æ¶ˆæ¯æ•°é‡: {len(messages)}")
        print(f"   - ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)} å­—ç¬¦")

        yield {
            "type": "api_request_started",
            "iteration": iteration,
            "message_count": len(messages)
        }

        try:
            response = await self._call_ai_with_tools(messages, system_prompt, ai_config)

            if not response:
                raise ValueError("AI è¿”å›ç©ºå“åº”")

            # 4. è§£æ AI å“åº”
            assistant_content = response.get("content", "")
            tool_calls_api = response.get("tool_calls", [])

            print(f"ğŸ“¥ æ”¶åˆ° AI å“åº”")
            print(f"   - å“åº”å†…å®¹é•¿åº¦: {len(assistant_content)} å­—ç¬¦")
            print(f"   - å·¥å…·è°ƒç”¨æ•°é‡: {len(tool_calls_api)}")

            if assistant_content:
                preview = assistant_content[:100] + "..." if len(assistant_content) > 100 else assistant_content
                print(f"   - å†…å®¹é¢„è§ˆ: {preview}")

            yield {
                "type": "api_response",
                "content": assistant_content,
                "iteration": iteration
            }

            # 5. ä¿å­˜ AI å“åº”åˆ°å†å²
            self.conversation_history.append({
                "role": "assistant",
                "content": assistant_content
            })

            # 6. å¤„ç†å·¥å…·è°ƒç”¨
            if not tool_calls_api:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å¯èƒ½å®Œæˆ
                print(f"\nâœ¨ æ²¡æœ‰æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å¯èƒ½å·²å®Œæˆ")
                if assistant_content:
                    print(f"ğŸ“ æœ€ç»ˆå“åº”: {assistant_content[:200]}...")
                    yield {
                        "type": "completion",
                        "content": assistant_content,
                        "iteration": iteration
                    }
                return

            # 7. è½¬æ¢å·¥å…·è°ƒç”¨æ ¼å¼
            tool_calls = []
            for tc in tool_calls_api:
                try:
                    arguments = parse_tool_call_arguments(tc["arguments"])
                    tool_calls.append({
                        "name": tc["name"],
                        "parameters": arguments
                    })
                except Exception as e:
                    logger.error(f"è§£æå·¥å…·è°ƒç”¨å‚æ•°å¤±è´¥: {e}")

            if not tool_calls:
                logger.warning("å·¥å…·è°ƒç”¨è§£æå¤±è´¥ï¼Œè·³è¿‡")
                return

            # 8. æ‰§è¡Œå·¥å…·
            print(f"\nğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")

            for i, tc in enumerate(tool_calls, 1):
                tool_name = tc["name"]
                params = tc["parameters"]
                print(f"   {i}. {tool_name}")
                if params:
                    params_str = ", ".join([f"{k}={v}" for k, v in params.items()])
                    print(f"      å‚æ•°: {params_str}")

            yield {
                "type": "tool_calls_detected",
                "tool_calls": tool_calls,
                "iteration": iteration
            }

            # 9. æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
            tool_results = []

            for tool_call_dict in tool_calls:
                tool_name = tool_call_dict.get("name")
                print(f"\nâš™ï¸  æ‰§è¡Œå·¥å…·: {tool_name}")

                # æµå¼è¿”å›å·¥å…·æ‰§è¡Œè¿›åº¦
                yield {
                    "type": "tool_execution_started",
                    "tool_name": tool_name,
                    "iteration": iteration
                }

                # æ‰§è¡Œå·¥å…·
                result = await self._execute_tool(tool_call_dict, context)

                # æ‰“å°æ‰§è¡Œç»“æœ
                if result["success"]:
                    print(f"   âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
                    data = result.get("data")
                    if data:
                        data_str = str(data)
                        if len(data_str) > 200:
                            print(f"   ğŸ“Š ç»“æœ: {data_str[:200]}...")
                        else:
                            print(f"   ğŸ“Š ç»“æœ: {data_str}")
                else:
                    print(f"   âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {result.get('error', 'Unknown error')}")

                yield {
                    "type": "tool_execution_completed",
                    "tool_name": tool_name,
                    "result": result,
                    "iteration": iteration
                }

                tool_results.append(result)

            # 10. å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
            formatted_results = self._format_tool_results_for_ai(tool_results)
            self.conversation_history.append({
                "role": "user",
                "content": formatted_results
            })

        except Exception as e:
            print(f"\nâŒ è¯·æ±‚æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(f"è¯·æ±‚æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield {
                "type": "error",
                "message": str(e),
                "iteration": iteration
            }

    async def _build_messages(
        self,
        user_content: List[Dict[str, Any]],
        ai_config: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆå¸¦ä¸Šä¸‹æ–‡å‹ç¼©ï¼‰

        å‚è€ƒ Cline çš„å®ç°ï¼Œåœ¨æ„å»ºæ¶ˆæ¯å‰æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
        """
        messages = []

        # æ·»åŠ å†å²æ¶ˆæ¯
        for msg in self.conversation_history:
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })

        # æ·»åŠ å½“å‰ç”¨æˆ·å†…å®¹
        for content in user_content:
            if content["type"] == "text":
                messages.append({
                    "role": "user",
                    "content": content["text"]
                })

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ä¸Šä¸‹æ–‡
        model = ai_config.get("ai_model", "deepseek-chat")

        if self.compression_strategy.must_compress(messages, model):
            print(f"\nâš ï¸  ä¸Šä¸‹æ–‡å³å°†æº¢å‡ºï¼Œè§¦å‘å‹ç¼©...")

            # å‹ç¼©å¯¹è¯å†å²
            compressed = await self.compression_strategy.compress_conversation_history(
                messages,
                model,
                ai_config
            )

            # æ›´æ–°å¯¹è¯å†å²ï¼ˆä¿ç•™å‹ç¼©åçš„ç‰ˆæœ¬ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œåªæ›´æ–°ç”¨äº API è¯·æ±‚çš„æ¶ˆæ¯ï¼Œä¸ç›´æ¥ä¿®æ”¹ self.conversation_history
            # å› ä¸ºè¿˜éœ€è¦ä¿ç•™å®Œæ•´å†å²ç”¨äºå…¶ä»–ç›®çš„

            print(f"âœ… ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆ")

            # è¿”å›å‹ç¼©åçš„æ¶ˆæ¯
            return compressed

        elif self.compression_strategy.should_compress(messages, model):
            print(f"\nâš¡  ä¸Šä¸‹æ–‡ä½¿ç”¨é‡è¾ƒé«˜ï¼Œå»ºè®®å‹ç¼©")
            info = self.token_counter.get_compression_info(messages, model)
            print(f"   - å½“å‰ä½¿ç”¨: {info['estimated_tokens']} tokens ({info['usage_percentage']*100:.1f}%)")
            print(f"   - æœ€å¤§å…è®¸: {info['max_allowed']} tokens")

        return messages

    async def _call_ai(
        self,
        messages: List[Dict[str, Any]],
        system_prompt: str,
        ai_config: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ AIï¼ˆæ™®é€šæ¨¡å¼ï¼Œä¸ä½¿ç”¨å·¥å…·ï¼‰"""
        try:
            response = await self.ai_manager.chat(
                provider=ai_config["ai_provider"],
                model=ai_config["ai_model"],
                messages=messages,
                api_key=ai_config["ai_api_key"],
                base_url=ai_config.get("ai_base_url"),
                temperature=ai_config.get("temperature", 0.7),
                max_tokens=ai_config.get("max_tokens", 4000),
                system_prompt=system_prompt
            )

            return response

        except Exception as e:
            logger.error(f"AI è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            return None

    async def _call_ai_with_tools(
        self,
        messages: List[Dict[str, Any]],
        system_prompt: str,
        ai_config: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ AIï¼ˆä½¿ç”¨ Tools APIï¼‰"""
        try:
            response = await self.ai_manager.chat_with_tools(
                provider=ai_config["ai_provider"],
                model=ai_config["ai_model"],
                messages=messages,
                api_key=ai_config["ai_api_key"],
                tools=self.tools_definition,
                base_url=ai_config.get("ai_base_url"),
                temperature=ai_config.get("temperature", 0.7),
                max_tokens=ai_config.get("max_tokens", 4000),
                system_prompt=system_prompt
            )

            return response

        except Exception as e:
            logger.error(f"AI è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            return None

    async def _execute_tool(
        self,
        tool_call_dict: Dict[str, Any],
        context: ToolContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        tool_name = tool_call_dict.get("name")
        parameters = tool_call_dict.get("parameters", {})

        # åˆ›å»º ToolCall å¯¹è±¡
        tool_call = ToolCall(
            id=str(uuid.uuid4()),
            name=tool_name,
            parameters=parameters
        )

        # æ‰§è¡Œå·¥å…·
        result = await self.tool_coordinator.execute(tool_call, context)

        # è¿”å›æ ¼å¼åŒ–ç»“æœ
        return {
            "tool": tool_name,
            "success": result.success,
            "data": result.data,
            "error": result.error
        }

    def _format_tool_results_for_ai(self, results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å·¥å…·ç»“æœç”¨äº AI ç†è§£ï¼ˆä½¿ç”¨ XML æ ¼å¼ï¼‰"""
        formatted = []

        for result in results:
            tool_name = result["tool"]

            if result["success"]:
                # ä½¿ç”¨ XML æ ¼å¼è¿”å›æˆåŠŸç»“æœ
                formatted.append(f"<response>")
                formatted.append(f"<tool>{tool_name}</tool>")
                formatted.append(f"<status>success</status>")

                # æ ¼å¼åŒ–æ•°æ®
                if result["data"]:
                    data_str = json.dumps(result["data"], ensure_ascii=False, indent=2)
                    formatted.append(f"<data>")
                    formatted.append(f"```json\n{data_str}\n```")
                    formatted.append(f"</data>")

                formatted.append(f"</response>")
            else:
                # ä½¿ç”¨ XML æ ¼å¼è¿”å›å¤±è´¥ç»“æœ
                formatted.append(f"<response>")
                formatted.append(f"<tool>{tool_name}</tool>")
                formatted.append(f"<status>error</status>")
                formatted.append(f"<error>{result.get('error', 'Unknown error')}</error>")
                formatted.append(f"</response>")

            formatted.append("")  # ç©ºè¡Œåˆ†éš”

        return "\n".join(formatted)

    def abort(self):
        """ä¸­æ­¢å½“å‰ä»»åŠ¡"""
        logger.info("ä¸­æ­¢ä»»åŠ¡")
        self.task_state.abort = True
