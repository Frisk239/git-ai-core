"""
ä»»åŠ¡æ‰§è¡Œå¼•æ“ - å€Ÿé‰´ Cline çš„é€’å½’ä»»åŠ¡å¾ªç¯æ¶æ„

è¿™æ˜¯æ ¸å¿ƒçš„ä»»åŠ¡æ‰§è¡Œå™¨ï¼Œè´Ÿè´£ï¼š
1. å¯åŠ¨ä»»åŠ¡
2. é€’å½’ä»»åŠ¡å¾ªç¯
3. å·¥å…·è°ƒç”¨ç®¡ç†
4. é”™è¯¯å¤„ç†å’Œé‡è¯•
"""

import json
import logging
import uuid
from typing import Dict, Any, List, Optional, AsyncIterator

from app.core.ai_manager import AIManager
from app.core.tools import (
    ToolCoordinator,
    ToolCall,
    ToolContext,
    get_tool_coordinator
)
from app.core.task.task_state import TaskState
from app.core.task.tools_converter import tools_to_openai_functions, parse_tool_call_arguments
from app.core.task.prompt_builder import PromptBuilder
from app.core.context import TokenCounter, CompressionStrategy
from app.core.context.conversation_history import ConversationHistoryManager, ToolCall
from app.core.context.task_history import TaskHistoryManager


logger = logging.getLogger(__name__)


class TaskEngine:
    """
    ä»»åŠ¡æ‰§è¡Œå¼•æ“ - Git AI Core çš„æ ¸å¿ƒ

    ç±»ä¼¼ Cline çš„ Task ç±»ï¼Œå®ç°é€’å½’ä»»åŠ¡å¾ªç¯
    """

    def __init__(
        self,
        ai_manager: Optional[AIManager] = None,
        tool_coordinator: Optional[ToolCoordinator] = None,
        max_iterations: int = 999,  # å–æ¶ˆè¿­ä»£é™åˆ¶ï¼Œè®¾ç½®ä¸ºå¾ˆå¤§çš„å€¼
        max_consecutive_mistakes: int = 3
    ):
        self.ai_manager = ai_manager or AIManager()
        self.tool_coordinator = tool_coordinator or get_tool_coordinator()
        self.prompt_builder = PromptBuilder(self.tool_coordinator)
        # ğŸ”¥ ç§»é™¤è¿™é‡Œçš„ tools_definition åˆå§‹åŒ–ï¼Œæ”¹ä¸ºæ¯æ¬¡æ‰§è¡Œä»»åŠ¡æ—¶åŠ¨æ€è·å–
        # self.tools_definition = tools_to_openai_functions(self.tool_coordinator)

        # ä¸Šä¸‹æ–‡ç®¡ç†
        self.token_counter = TokenCounter()
        self.compression_strategy = CompressionStrategy(self.ai_manager)

        # å¯¹è¯å†å²ç®¡ç†å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.history_manager: Optional[ConversationHistoryManager] = None

        # ä»»åŠ¡å†å²ç®¡ç†å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.task_history_manager: Optional[TaskHistoryManager] = None

        # é…ç½®
        self.max_iterations = max_iterations
        self.max_consecutive_mistakes = max_consecutive_mistakes

        # ä»»åŠ¡çŠ¶æ€
        self.task_state = TaskState()
        self.conversation_history = []  # å…¼å®¹æ—§ä»£ç ï¼Œåç»­ç§»é™¤

    async def execute_task(
        self,
        user_input: str,
        repository_path: str,
        ai_config: Dict[str, Any],
        task_id: Optional[str] = None,  # æ”¯æŒç»§ç»­ç°æœ‰ä»»åŠ¡
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        æ‰§è¡Œä»»åŠ¡ - ä¸»å…¥å£ç‚¹

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            repository_path: Git ä»“åº“è·¯å¾„
            ai_config: AI é…ç½®
            task_id: å¯é€‰çš„ä»»åŠ¡ ID,ç”¨äºç»§ç»­ç°æœ‰ä»»åŠ¡(å®ç°è®°å¿†åŠŸèƒ½)

        Yields:
            ä»»åŠ¡è¿›åº¦ä¿¡æ¯ï¼ˆç”¨äºæµå¼å“åº”ï¼‰
        """
        # å¦‚æœæ²¡æœ‰æä¾› task_id,ç”Ÿæˆæ–°çš„
        is_new_task = task_id is None
        if is_new_task:
            task_id = str(uuid.uuid4())[:8]

        print("\n" + "="*80)
        if is_new_task:
            print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡")
        else:
            print(f"ğŸ”„ ç»§ç»­ä»»åŠ¡ (è®°å¿†æ¨¡å¼)")
        print("="*80)
        print(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
        print(f"ğŸ“ ä»“åº“è·¯å¾„: {repository_path}")
        print(f"ğŸ†” ä»»åŠ¡ ID: {task_id}")
        print(f"ğŸ¤– AI é…ç½®: {ai_config.get('ai_provider')} - {ai_config.get('ai_model')}")
        print("="*80 + "\n")

        logger.info(f"=== {'å¼€å§‹æ–°ä»»åŠ¡' if is_new_task else 'ç»§ç»­ä»»åŠ¡'} (ID: {task_id}) ===")
        logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
        logger.info(f"ä»“åº“è·¯å¾„: {repository_path}")

        # 1. åˆå§‹åŒ–ä»»åŠ¡å†å²ç®¡ç†å™¨
        self.task_history_manager = TaskHistoryManager(
            workspace_path=repository_path
        )
        await self.task_history_manager.load_history()

        # 2. åˆå§‹åŒ–å¯¹è¯å†å²ç®¡ç†å™¨
        self.history_manager = ConversationHistoryManager(
            task_id=task_id,
            workspace_path=repository_path
        )

        # å°è¯•åŠ è½½å†å²è®°å½•ï¼ˆæ¢å¤ä»»åŠ¡ï¼‰
        loaded_history = await self.history_manager.load_history()
        if loaded_history:
            print(f"[INFO] å·²åŠ è½½ä»»åŠ¡å†å²: {len(self.history_manager.messages)} æ¡æ¶ˆæ¯")
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå°†å†å²æ¶ˆæ¯å¤åˆ¶åˆ° conversation_historyï¼Œè¿™æ · _build_messages æ‰èƒ½ä½¿ç”¨
            self.conversation_history = [
                {
                    "role": msg.role,
                    "content": msg.content
                }
                for msg in self.history_manager.messages
            ]
            print(f"[INFO] å·²å°† {len(self.conversation_history)} æ¡å†å²æ¶ˆæ¯åŠ è½½åˆ°ä¸Šä¸‹æ–‡")

        # 3. æ·»åŠ æˆ–æ›´æ–°ä»»åŠ¡åˆ°å†å²åˆ—è¡¨
        task_description = user_input[:100] + "..." if len(user_input) > 100 else user_input
        history_item = self.task_history_manager.add_or_update_task(
            task_id=task_id,
            task_description=task_description,
            api_provider=ai_config.get("ai_provider"),
            api_model=ai_config.get("ai_model"),
            repository_path=repository_path,
        )
        print(f"[INFO] ä»»åŠ¡ ID: {task_id}")

        # 4. åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        self.task_state.reset_for_new_task()
        context = ToolContext(
            repository_path=repository_path,
            conversation_history=[],
            metadata={"ai_config": ai_config, "task_id": task_id}
        )

        # 5. å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å†å²
        self.history_manager.append_message(
            role="user",
            content=f"<task>\n{user_input}\n</task>"
        )
        # ğŸ”¥ åŒæ—¶æ›´æ–° conversation_historyï¼ˆç”¨äºåç»­çš„ API è°ƒç”¨ï¼‰
        self.conversation_history.append({
            "role": "user",
            "content": f"<task>\n{user_input}\n</task>"
        })

        # 6. æ„å»ºåˆå§‹ç”¨æˆ·æ¶ˆæ¯
        user_content = [{
            "type": "text",
            "text": f"<task>\n{user_input}\n</task>"
        }]

        # 5. å¯åŠ¨ä»»åŠ¡å¾ªç¯
        try:
            # é¦–å…ˆå‘é€ä»»åŠ¡ ID äº‹ä»¶(è®©å‰ç«¯çŸ¥é“å½“å‰ä»»åŠ¡ ID)
            yield {
                "type": "task_started",
                "task_id": task_id,
                "is_new_task": is_new_task
            }

            async for event in self._task_loop(user_content, context, ai_config):
                yield event
        except Exception as e:
            print(f"\n{'='*80}")
            print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            print(f"{'='*80}\n")
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield {
                "type": "error",
                "message": f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            }

        # 7. ä¿å­˜å¯¹è¯å†å²å’Œä»»åŠ¡å†å²
        finally:
            # ä¿å­˜å¯¹è¯å†å²
            if self.history_manager:
                success = await self.history_manager.save_history()
                if success:
                    stats = self.history_manager.get_stats()
                    print(f"\nğŸ’¾ å¯¹è¯å†å²å·²ä¿å­˜:")
                    print(f"   - æ€»æ¶ˆæ¯æ•°: {stats['total_messages']}")
                    print(f"   - ç”¨æˆ·æ¶ˆæ¯: {stats['user_messages']}")
                    print(f"   - AI æ¶ˆæ¯: {stats['assistant_messages']}")
                    print(f"   - æ€» tokens: {stats['total_tokens']}")

            # æ›´æ–°å¹¶ä¿å­˜ä»»åŠ¡å†å²ç»Ÿè®¡
            if self.task_history_manager:
                # æ›´æ–°å½“å‰ä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯
                history_item = self.task_history_manager.get_task(task_id)
                if history_item and self.history_manager:
                    # æ›´æ–° token ç»Ÿè®¡
                    stats = self.history_manager.get_stats()
                    history_item.tokens_in = stats['total_tokens'] // 2  # ä¼°ç®—
                    history_item.tokens_out = stats['total_tokens'] - history_item.tokens_in
                    history_item.size = stats.get('task_dir_size', 0)

                # ä¿å­˜ä»»åŠ¡å†å²åˆ—è¡¨
                await self.task_history_manager.save_history()

        print("\n" + "="*80)
        print("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
        print("="*80 + "\n")

        logger.info(f"=== ä»»åŠ¡ç»“æŸ ===")

    async def _task_loop(
        self,
        initial_user_content: List[Dict[str, Any]],
        context: ToolContext,
        ai_config: Dict[str, Any]
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        é€’å½’ä»»åŠ¡å¾ªç¯ - æ ¸å¿ƒé€»è¾‘

        ç±»ä¼¼ Cline çš„ initiateTaskLoop + recursivelyMakeClineRequests
        """
        next_user_content = initial_user_content
        iteration = 0

        while iteration < self.max_iterations:
            iteration += 1

            # æ£€æŸ¥ä¸­æ­¢æ ‡å¿—
            if self.task_state.should_abort():
                print(f"\nâš ï¸  ä»»åŠ¡è¢«ä¸­æ­¢")
                logger.info("ä»»åŠ¡è¢«ä¸­æ­¢")
                yield {
                    "type": "aborted",
                    "iteration": iteration
                }
                break

            # æ£€æŸ¥é”™è¯¯æ¬¡æ•°
            if self.task_state.consecutive_mistake_count >= self.max_consecutive_mistakes:
                print(f"\nâŒ è¾¾åˆ°æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°: {self.task_state.consecutive_mistake_count}")
                logger.error(f"è¾¾åˆ°æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°: {self.task_state.consecutive_mistake_count}")
                yield {
                    "type": "error",
                    "message": f"è¾¾åˆ°æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•° ({self.task_state.consecutive_mistake_count})",
                    "iteration": iteration
                }
                break

            print(f"\n{'â”€'*80}")
            print(f"ğŸ”„ è¿­ä»£ {iteration}/{self.max_iterations}")
            print(f"{'â”€'*80}\n")

            logger.info(f"=== è¿­ä»£ {iteration} ===")

            # æ‰§è¡Œå•æ¬¡è¯·æ±‚
            did_end_loop = False
            async for event in self._execute_single_request(next_user_content, context, ai_config, iteration):
                yield event

                # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                if event.get("type") == "completion":
                    did_end_loop = True
                elif event.get("type") == "error":
                    self.task_state.increment_mistake_count()

            if did_end_loop:
                print(f"\nâœ… ä»»åŠ¡å®Œæˆï¼Œé€€å‡ºå¾ªç¯")
                logger.info("ä»»åŠ¡å®Œæˆ")
                break
            else:
                # ç»§ç»­å¾ªç¯ï¼Œæç¤º AI ä½¿ç”¨å·¥å…·
                next_user_content = [{
                    "type": "text",
                    "text": "è¯·ä½¿ç”¨å·¥å…·æ¥å®Œæˆä»»åŠ¡ï¼Œæˆ–è€…å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ã€‚"
                }]

    async def _execute_single_request(
        self,
        user_content: List[Dict[str, Any]],
        context: ToolContext,
        ai_config: Dict[str, Any],
        iteration: int
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        æ‰§è¡Œå•æ¬¡ API è¯·æ±‚ï¼ˆä½¿ç”¨ Tools APIï¼‰

        ç±»ä¼¼ Cline çš„ attemptApiRequest + å·¥å…·æ‰§è¡Œ
        """
        # 1. æ„å»ºæ¶ˆæ¯å†å²ï¼ˆå¸¦ä¸Šä¸‹æ–‡å‹ç¼©ï¼‰
        messages = await self._build_messages(user_content, ai_config)

        # 2. ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
        system_prompt = await self.prompt_builder.build_prompt(context)

        # 3. è°ƒç”¨ AIï¼ˆä½¿ç”¨ Tools APIï¼‰
        self.task_state.increment_api_request_count()

        print(f"ğŸ“¤ å‘é€ API è¯·æ±‚...")
        print(f"   - æ¶ˆæ¯æ•°é‡: {len(messages)}")
        print(f"   - ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)} å­—ç¬¦")

        yield {
            "type": "api_request_started",
            "iteration": iteration,
            "message_count": len(messages)
        }

        try:
            response = await self._call_ai_with_tools(messages, system_prompt, ai_config)

            if not response:
                raise ValueError("AI è¿”å›ç©ºå“åº”")

            # 4. è§£æ AI å“åº”
            assistant_content = response.get("content", "")
            tool_calls_api = response.get("tool_calls", [])

            print(f"ğŸ“¥ æ”¶åˆ° AI å“åº”")
            print(f"   - å“åº”å†…å®¹é•¿åº¦: {len(assistant_content)} å­—ç¬¦")
            print(f"   - å·¥å…·è°ƒç”¨æ•°é‡: {len(tool_calls_api)}")

            if assistant_content:
                preview = assistant_content[:100] + "..." if len(assistant_content) > 100 else assistant_content
                print(f"   - å†…å®¹é¢„è§ˆ: {preview}")

            yield {
                "type": "api_response",
                "content": assistant_content,
                "iteration": iteration
            }

            # 5. ä¿å­˜ AI å“åº”åˆ°å†å²è®°å½•
            if self.history_manager:
                # è½¬æ¢å·¥å…·è°ƒç”¨æ ¼å¼
                tool_calls_for_history = None
                if tool_calls_api:
                    tool_calls_for_history = [
                        ToolCall(
                            id=str(uuid.uuid4()),
                            name=tc["name"],
                            parameters=parse_tool_call_arguments(tc["arguments"]),
                            result=None,  # å·¥å…·ç»“æœç¨åæ·»åŠ 
                        )
                        for tc in tool_calls_api
                    ]

                self.history_manager.append_message(
                    role="assistant",
                    content=assistant_content,
                    tool_calls=tool_calls_for_history,
                    model=ai_config.get("ai_model"),
                )

            # 6. å…¼å®¹æ—§ä»£ç 
            self.conversation_history.append({
                "role": "assistant",
                "content": assistant_content
            })

            # 7. å¤„ç†å·¥å…·è°ƒç”¨
            if not tool_calls_api:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å¯èƒ½å®Œæˆ
                print(f"\nâœ¨ æ²¡æœ‰æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å¯èƒ½å·²å®Œæˆ")
                if assistant_content:
                    print(f"ğŸ“ æœ€ç»ˆå“åº”: {assistant_content[:200]}...")
                    yield {
                        "type": "completion",
                        "content": assistant_content,
                        "iteration": iteration
                    }
                return

            # 7. è½¬æ¢å·¥å…·è°ƒç”¨æ ¼å¼
            tool_calls = []
            for tc in tool_calls_api:
                try:
                    arguments = parse_tool_call_arguments(tc["arguments"])
                    tool_calls.append({
                        "name": tc["name"],
                        "parameters": arguments
                    })
                except Exception as e:
                    logger.error(f"è§£æå·¥å…·è°ƒç”¨å‚æ•°å¤±è´¥: {e}")

            if not tool_calls:
                logger.warning("å·¥å…·è°ƒç”¨è§£æå¤±è´¥ï¼Œè·³è¿‡")
                return

            # 8. æ‰§è¡Œå·¥å…·
            print(f"\nğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨:")

            for i, tc in enumerate(tool_calls, 1):
                tool_name = tc["name"]
                params = tc["parameters"]
                print(f"   {i}. {tool_name}")
                if params:
                    params_str = ", ".join([f"{k}={v}" for k, v in params.items()])
                    print(f"      å‚æ•°: {params_str}")

            yield {
                "type": "tool_calls_detected",
                "tool_calls": tool_calls,
                "iteration": iteration
            }

            # 9. æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
            tool_results = []
            has_completion_tool = False

            for tool_call_dict in tool_calls:
                tool_name = tool_call_dict.get("name")
                print(f"\nâš™ï¸  æ‰§è¡Œå·¥å…·: {tool_name}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯ attempt_completion å·¥å…·
                if tool_name == "attempt_completion":
                    has_completion_tool = True

                # æµå¼è¿”å›å·¥å…·æ‰§è¡Œè¿›åº¦
                yield {
                    "type": "tool_execution_started",
                    "tool_name": tool_name,
                    "iteration": iteration
                }

                # æ‰§è¡Œå·¥å…·
                result = await self._execute_tool(tool_call_dict, context)

                # æ‰“å°æ‰§è¡Œç»“æœ
                if result["success"]:
                    print(f"   âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
                    data = result.get("data")
                    if data:
                        data_str = str(data)
                        if len(data_str) > 200:
                            print(f"   ğŸ“Š ç»“æœ: {data_str[:200]}...")
                        else:
                            print(f"   ğŸ“Š ç»“æœ: {data_str}")
                else:
                    print(f"   âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {result.get('error', 'Unknown error')}")

                yield {
                    "type": "tool_execution_completed",
                    "tool_name": tool_name,
                    "result": result,
                    "iteration": iteration
                }

                tool_results.append(result)

                # æ›´æ–°å†å²è®°å½•ä¸­çš„å·¥å…·ç»“æœ
                if self.history_manager and self.history_manager.messages:
                    last_message = self.history_manager.messages[-1]
                    if last_message.tool_calls and len(last_message.tool_calls) >= len(tool_results):
                        tool_call_index = len(tool_results) - 1
                        last_message.tool_calls[tool_call_index].result = result

            # 10. æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº† attempt_completion
            if has_completion_tool:
                yield {
                    "type": "completion",
                    "result": tool_results[-1].get("data", {}),
                    "iteration": iteration
                }
                return

            # 10. å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
            formatted_results = self._format_tool_results_for_ai(tool_results)
            self.conversation_history.append({
                "role": "user",
                "content": formatted_results
            })

        except Exception as e:
            print(f"\nâŒ è¯·æ±‚æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(f"è¯·æ±‚æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield {
                "type": "error",
                "message": str(e),
                "iteration": iteration
            }

    async def _build_messages(
        self,
        user_content: List[Dict[str, Any]],
        ai_config: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆå¸¦ä¸Šä¸‹æ–‡å‹ç¼©å’Œå­—ç¬¦æ•°é™åˆ¶ï¼‰

        å‚è€ƒ Clineï¼šå·¥å…·è°ƒç”¨å†å²ä¼šè¢«è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼åŒ…å«åœ¨æ¶ˆæ¯ä¸­
        """
        messages = []

        # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼‰
        if self.history_manager and self.history_manager.messages:
            for msg in self.history_manager.messages:
                # æ„å»ºæ¶ˆæ¯å†…å®¹
                content_parts = [msg.content]

                # ğŸ”¥ å…³é”®ï¼šå¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè½¬æ¢ä¸ºå¯è¯»çš„æ–‡æœ¬æ ¼å¼
                # å‚è€ƒ Clineï¼šå·¥å…·è°ƒç”¨ä¼šä»¥ "tool_name: params Result: result" çš„æ ¼å¼æ˜¾ç¤º
                if msg.tool_calls:
                    for tc in msg.tool_calls:
                        # ç”Ÿæˆå·¥å…·æè¿°ï¼ˆå¦‚ "read file: xxx"ï¼‰
                        tool_desc = self._get_tool_description(tc)

                        # æ·»åŠ å·¥å…·è°ƒç”¨ä¿¡æ¯åˆ°å†…å®¹ä¸­
                        content_parts.append(f"\n\n[å·¥å…·è°ƒç”¨] {tool_desc}")

                        # å¦‚æœæœ‰ç»“æœï¼Œæ·»åŠ ç»“æœ
                        if tc.result:
                            if tc.result.get("success"):
                                result_content = tc.result.get("data", "")
                                # é™åˆ¶ç»“æœé•¿åº¦
                                if isinstance(result_content, str) and len(result_content) > 500:
                                    result_content = result_content[:500] + "\n...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
                                content_parts.append(f"\nç»“æœ: {result_content}")
                            else:
                                error_msg = tc.result.get("error", "Unknown error")
                                content_parts.append(f"\né”™è¯¯: {error_msg}")

                # åˆå¹¶æ‰€æœ‰å†…å®¹éƒ¨åˆ†
                full_content = "\n".join(content_parts)

                messages.append({
                    "role": msg.role,
                    "content": full_content
                })
        else:
            # å…¼å®¹æ—§ä»£ç ï¼šä½¿ç”¨ conversation_history
            for msg in self.conversation_history:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

        # æ·»åŠ å½“å‰ç”¨æˆ·å†…å®¹
        for content in user_content:
            if content["type"] == "text":
                messages.append({
                    "role": "user",
                    "content": content["text"]
                })

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ä¸Šä¸‹æ–‡
        model = ai_config.get("ai_model", "deepseek-chat")

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ Cline çš„ä¸¤é˜¶æ®µå‹ç¼©ç­–ç•¥
        # 1. å…ˆä¼˜åŒ–é‡å¤æ–‡ä»¶è¯»å–ï¼ˆä¸åˆ é™¤æ¶ˆæ¯ï¼Œåªæ›¿æ¢å†…å®¹ï¼‰
        # 2. å¦‚æœä»ç„¶è¶…é™ï¼Œå†è¿›è¡Œä¸‰æ˜æ²»æˆªæ–­
        if self.compression_strategy.must_compress(messages, model):
            print(f"\nâš ï¸  ä¸Šä¸‹æ–‡å³å°†æº¢å‡ºï¼Œè§¦å‘å‹ç¼©...")

            # ä½¿ç”¨æ–°çš„å‹ç¼©ç­–ç•¥ï¼ˆåŒ…å«æ–‡ä»¶è¯»å–ä¼˜åŒ–ï¼‰
            compressed = await self.compression_strategy.compress_conversation_history(
                messages,
                model,
                ai_config
            )

            print(f"âœ… ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆ")

            # è¿”å›å‹ç¼©åçš„æ¶ˆæ¯
            return compressed

        elif self.compression_strategy.should_compress(messages, model):
            print(f"\nâš¡ ä¸Šä¸‹æ–‡ä½¿ç”¨é‡è¾ƒé«˜ï¼Œå»ºè®®å‹ç¼©")
            info = self.token_counter.get_compression_info(messages, model)
            print(f"   - å½“å‰ä½¿ç”¨: {info['estimated_tokens']} tokens ({info['usage_percentage']*100:.1f}%)")
            print(f"   - æœ€å¤§å…è®¸: {info['max_allowed']} tokens")

        return messages

    def _get_tool_description(self, tool_call: ToolCall) -> str:
        """
        ç”Ÿæˆå·¥å…·è°ƒç”¨çš„å‹å¥½æè¿°

        å‚è€ƒ Cline çš„æ ¼å¼ï¼š
        - read file: xxx
        - write to file: xxx
        - search_files: xxx

        Args:
            tool_call: å·¥å…·è°ƒç”¨å¯¹è±¡

        Returns:
            å·¥å…·æè¿°å­—ç¬¦ä¸²
        """
        tool_name = tool_call.name
        params = tool_call.parameters

        # æ ¹æ®å·¥å…·åç§°ç”Ÿæˆæè¿°
        if tool_name == "read_file":
            file_path = params.get("file_path", "")
            return f"è¯»å–æ–‡ä»¶: {file_path}"

        elif tool_name == "write_to_file":
            file_path = params.get("file_path", "")
            return f"å†™å…¥æ–‡ä»¶: {file_path}"

        elif tool_name == "modify_file":
            file_path = params.get("file_path", "")
            return f"ä¿®æ”¹æ–‡ä»¶: {file_path}"

        elif tool_name == "list_directory":
            path = params.get("path", "")
            recursive = params.get("recursive", False)
            return f"åˆ—å‡ºç›®å½•: {path} (é€’å½’: {recursive})"

        elif tool_name == "search_files":
            path = params.get("path", "")
            pattern = params.get("pattern", "")
            return f"æœç´¢æ–‡ä»¶: {path} (æ¨¡å¼: {pattern})"

        elif tool_name == "list_code_definitions":
            file_path = params.get("file_path", "")
            return f"åˆ—å‡ºä»£ç å®šä¹‰: {file_path}"

        elif tool_name == "git_status":
            return "æŸ¥çœ‹ Git çŠ¶æ€"

        elif tool_name == "git_diff":
            file_path = params.get("file_path", "")
            return f"æŸ¥çœ‹ Git å·®å¼‚: {file_path}"

        elif tool_name == "git_log":
            return "æŸ¥çœ‹ Git æäº¤å†å²"

        elif tool_name == "attempt_completion":
            return "å®Œæˆä»»åŠ¡"

        else:
            # é€šç”¨æ ¼å¼
            return f"{tool_name}: {params}"

    async def _call_ai(
        self,
        messages: List[Dict[str, Any]],
        system_prompt: str,
        ai_config: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ AIï¼ˆæ™®é€šæ¨¡å¼ï¼Œä¸ä½¿ç”¨å·¥å…·ï¼‰"""
        try:
            response = await self.ai_manager.chat(
                provider=ai_config["ai_provider"],
                model=ai_config["ai_model"],
                messages=messages,
                api_key=ai_config["ai_api_key"],
                base_url=ai_config.get("ai_base_url"),
                temperature=ai_config.get("temperature", 0.7),
                max_tokens=ai_config.get("max_tokens", 4000),
                system_prompt=system_prompt
            )

            return response

        except Exception as e:
            logger.error(f"AI è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            return None

    async def _call_ai_with_tools(
        self,
        messages: List[Dict[str, Any]],
        system_prompt: str,
        ai_config: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ AIï¼ˆä½¿ç”¨ Tools APIï¼‰"""
        try:
            # ğŸ”¥ æ¯æ¬¡è°ƒç”¨ AI æ—¶åŠ¨æ€è·å–æœ€æ–°çš„å·¥å…·å®šä¹‰ï¼ˆæ”¯æŒè¿è¡Œæ—¶æ·»åŠ /åˆ é™¤ MCP å·¥å…·ï¼‰
            tools_definition = tools_to_openai_functions(self.tool_coordinator)

            response = await self.ai_manager.chat_with_tools(
                provider=ai_config["ai_provider"],
                model=ai_config["ai_model"],
                messages=messages,
                api_key=ai_config["ai_api_key"],
                tools=tools_definition,  # ğŸ”¥ ä½¿ç”¨åŠ¨æ€è·å–çš„å·¥å…·å®šä¹‰
                base_url=ai_config.get("ai_base_url"),
                temperature=ai_config.get("temperature", 0.7),
                max_tokens=ai_config.get("max_tokens", 4000),
                system_prompt=system_prompt
            )

            return response

        except Exception as e:
            logger.error(f"AI è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            return None

    async def _execute_tool(
        self,
        tool_call_dict: Dict[str, Any],
        context: ToolContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        tool_name = tool_call_dict.get("name")
        parameters = tool_call_dict.get("parameters", {})

        # åˆ›å»º ToolCall å¯¹è±¡
        tool_call = ToolCall(
            id=str(uuid.uuid4()),
            name=tool_name,
            parameters=parameters
        )

        # æ‰§è¡Œå·¥å…·
        result = await self.tool_coordinator.execute(tool_call, context)

        # è¿”å›æ ¼å¼åŒ–ç»“æœ
        return {
            "tool": tool_name,
            "success": result.success,
            "data": result.data,
            "error": result.error
        }

    def _format_tool_results_for_ai(self, results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å·¥å…·ç»“æœç”¨äº AI ç†è§£ï¼ˆä½¿ç”¨ XML æ ¼å¼ï¼‰"""
        formatted = []

        for result in results:
            tool_name = result["tool"]

            if result["success"]:
                # ä½¿ç”¨ XML æ ¼å¼è¿”å›æˆåŠŸç»“æœ
                formatted.append(f"<response>")
                formatted.append(f"<tool>{tool_name}</tool>")
                formatted.append(f"<status>success</status>")

                # æ ¼å¼åŒ–æ•°æ®
                if result["data"]:
                    data = result["data"]

                    # å¦‚æœæ•°æ®å·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                    if isinstance(data, str):
                        data_str = data
                    # å¦‚æœæ•°æ®æ˜¯å­—å…¸æˆ–åˆ—è¡¨ï¼Œåºåˆ—åŒ–ä¸º JSON
                    elif isinstance(data, (dict, list)):
                        data_str = json.dumps(data, ensure_ascii=False, indent=2)
                    # å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    else:
                        data_str = str(data)

                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæˆªæ–­è¿‡å¤§çš„å·¥å…·ç»“æœï¼ˆå‚è€ƒ Clineï¼‰
                    # GLM æ¨¡å‹æœ‰å•æ¬¡è¯·æ±‚å­—ç¬¦æ•°é™åˆ¶ï¼ˆçº¦ 50,000 å­—ç¬¦ï¼‰
                    # è¿™é‡Œé™åˆ¶æ¯ä¸ªå·¥å…·ç»“æœæœ€å¤š 10,000 å­—ç¬¦
                    MAX_TOOL_RESULT_CHARS = 10_000
                    if len(data_str) > MAX_TOOL_RESULT_CHARS:
                        truncated_msg = f"\n\n[æ³¨æ„ï¼šç»“æœå·²æˆªæ–­ï¼ŒåŸé•¿åº¦ {len(data_str)} å­—ç¬¦ï¼Œæ˜¾ç¤ºå‰ {MAX_TOOL_RESULT_CHARS} å­—ç¬¦]"
                        data_str = data_str[:MAX_TOOL_RESULT_CHARS] + truncated_msg

                    formatted.append(f"<data>")
                    formatted.append(f"```\n{data_str}\n```")
                    formatted.append(f"</data>")

                formatted.append(f"</response>")
            else:
                # ä½¿ç”¨ XML æ ¼å¼è¿”å›å¤±è´¥ç»“æœ
                formatted.append(f"<response>")
                formatted.append(f"<tool>{tool_name}</tool>")
                formatted.append(f"<status>error</status>")
                formatted.append(f"<error>{result.get('error', 'Unknown error')}</error>")
                formatted.append(f"</response>")

            formatted.append("")  # ç©ºè¡Œåˆ†éš”

        return "\n".join(formatted)

    def abort(self):
        """ä¸­æ­¢å½“å‰ä»»åŠ¡"""
        logger.info("ä¸­æ­¢ä»»åŠ¡")
        self.task_state.abort = True
